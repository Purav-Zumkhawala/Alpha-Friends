{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dialogues extracted 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def extractData(filepath):\n",
    "    with open (filepath) as f:\n",
    "        data = json.loads(f.read())\n",
    "    required_data = {}\n",
    "    episodes_data = data[\"episodes\"]\n",
    "    for episode in episodes_data:\n",
    "        scenes_data = episode[\"scenes\"]\n",
    "        for scene in scenes_data:\n",
    "            dialogue_list = []\n",
    "            count_dict = {\"Total\":0,\"Ross Geller\":0, \"Rachel Green\":0, \"Monica Geller\":0, \"Chandler Bing\":0, \"Joey Tribbiani\":0,\"Phoebe Buffay\":0}\n",
    "            for utterance in scene[\"utterances\"]:\n",
    "                if len(utterance[\"speakers\"]) > 0:\n",
    "                    temp_list = [\",\".join(utterance[\"speakers\"]),utterance[\"transcript\"]]\n",
    "                    dialogue_list.append(temp_list)\n",
    "                    if temp_list[0] in list(count_dict.keys()):\n",
    "                        count_dict[temp_list[0]]+=1\n",
    "                        count_dict[\"Total\"]+=1\n",
    "            required_data[scene[\"scene_id\"]] = {\"dialogues\":dialogue_list,\"count\":count_dict}\n",
    "    return required_data\n",
    "\n",
    "def getSequenceWiseUtterences(filepath):\n",
    "    count=0\n",
    "    with open (filepath) as f:\n",
    "        data = json.loads(f.read())\n",
    "    dialogue_list = []\n",
    "    episodes_data = data[\"episodes\"]\n",
    "    for episode in episodes_data:\n",
    "        scenes_data = episode[\"scenes\"]\n",
    "        for scene in scenes_data:\n",
    "            for utterance in scene[\"utterances\"]:\n",
    "                if len(utterance[\"speakers\"]) > 0:\n",
    "                    count+=1\n",
    "                    dialogue_list.append(utterance[\"transcript\"])\n",
    "    return dialogue_list,count\n",
    "\n",
    "\n",
    "def getCharacterDialogues(filepath,character):\n",
    "    with open (filepath) as f:\n",
    "        data = json.loads(f.read())\n",
    "    episodes_data = data[\"episodes\"]\n",
    "    with open(character.split()[0]+'_dialogues_all.txt', 'a+') as result:\n",
    "        for episode in episodes_data:\n",
    "            scenes_data = episode[\"scenes\"]\n",
    "            for scene in scenes_data:\n",
    "                temp = \"\"\n",
    "                for utterance in scene[\"utterances\"]:\n",
    "                    if len(utterance[\"speakers\"]) > 0:\n",
    "                        if len(utterance[\"speakers\"]) == 1 and  character in utterance[\"speakers\"]:\n",
    "                            temp += \"<\"+character.split()[0]+\">\" + utterance[\"transcript\"] + \"<end\"+character.split()[0]+\">\"\n",
    "                        else:\n",
    "                            temp += utterance[\"transcript\"]\n",
    "                result.write(temp+\"\\n\")\n",
    "    \n",
    "        \n",
    "\n",
    "filepath = \"Raw Data\"\n",
    "filenames = os.listdir(filepath)\n",
    "storePath = \"\"\n",
    "tcount = 0\n",
    "\n",
    "if not os.path.exists(os.path.join(storePath,\"Dataset\")):\n",
    "    os.mkdir(\"Dataset\")\n",
    "if not os.path.exists(os.path.join(storePath,\"Sequence Utterances\")):\n",
    "    os.mkdir(\"Sequence Utterances\")\n",
    "    \n",
    "for i in filenames:\n",
    "    data_dict = extractData(os.path.join(filepath,i))\n",
    "    json_save_path = Path(os.path.join(storePath,\"Dataset\",i.split(\".\")[0][8:]+\".json\"))\n",
    "    json_save_path.write_text(json.dumps(data_dict))\n",
    "    dialogue_list,count = getSequenceWiseUtterences(os.path.join(filepath,i))\n",
    "    tcount+=count\n",
    "    \n",
    "    f = open(os.path.join(storePath,\"Sequence Utterances\",i.split(\".\")[0][8:]+\".txt\"), \"w\")\n",
    "    for dialog in dialogue_list:\n",
    "        f.write(dialog+\"\\n\")\n",
    "    f.close()\n",
    "#     Change character name to generate required data file for Vanilla GPT2 method\n",
    "    character = \"Ross Geller\"\n",
    "    getCharacterDialogues(os.path.join(filepath,i),character)\n",
    "    \n",
    "    \n",
    "print(\"Number of dialogues extracted\",tcount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
